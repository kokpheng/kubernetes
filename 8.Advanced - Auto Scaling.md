<h1 align="center">
  <br>
  <a href="https://kubernetes.io/"><img src="https://avatars1.githubusercontent.com/u/13629408?s=400&v=4" alt="Markdownify" width="200"></a>
  <br>
  Kubernetes
  <br>
</h1>

[![Submit Queue Widget]][Submit Queue] [![GoDoc Widget]][GoDoc] [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/569/badge)](https://bestpractices.coreinfrastructure.org/projects/569)

## ðŸš© Table of Contents

- [Introduction](#introduction)
- [What Is The Horizontal Pod Autoscaler?](#what-is-the-horizontal-pod-autoscaler)
- [Creating an HPA?](#creating-an-hpa)
- [Practical Example](#practical-example)
  1. [Apply wordpress deployment](#1-apply-wordpress-deployment)
  2. [Add an HPA to Enable Auto-Scaling](#2-add-an-hpa-to-enable-auto-scaling)
  3. [Simulate Using an Infinite HTTP Request Loop](#3-simulate-using-an-infinite-http-request-loop)
  4. [Check the HPA status](#4-check-the-hpa-status)
- [References](#-full-kubernetes-references--cheat-sheet)
- [Source Code Example](#-source-code-example)
- [Contributing](#-contributing)
- [License](#-license)

## Introduction

We have examined how to manually evaluate usage resource and performance in your Kubernetes cluster, you may recall now that Heapster is monitoring our cluster metrics like CPU usage, memory network and storage by pod are being tracked. That can provide you with valuable insights into the status of your application. But that data can also be used by Kubernetes to automatically provide scaling for your application to keep it performant when resource usages spike without any intervention from you. This processing system is called **Auto Scaling** and Kubernetes provides a facility called the **Horizontal Pod Auto Scaler** to scale the number of pods in your deployment to match usage needs.

[(Back to top)](#-table-of-contents)

## What Is The Horizontal Pod Autoscaler?

- The Horizontal Pod Autoscaler (HPA) is a Kubernetes facility that adjusts the number of replicas of a Pod to match observed average CPU utilization to a target specified by the user. In custom situations and scenarios custom metrics can be provided to go beyond CPU utilization, if youâ€™re willing to do a little bit of work to build a manual API. In plain English it means that Kubernetes will scale your pod and create more pods to meet demand within certain parameters. You can even specify those parameters or until you're at the physical limit of your cluster.

- There are a variety of configurable options - quite a few - the key takeaway is to know that HPA will create new Pods (or remove Pods) from a replica to maintain average CPU utilization across all Pods to a level specified when you create your HPA - subject to conditions you specify

[(Back to top)](#-table-of-contents)

## Creating an HPA?

`kubectl autoscale` provides the needed functions to create an HPA

- To create an autoscaler on our â€œwordpressâ€ deployment that targets CPU utilization to an average of 50% per Pod, within the parameters of a minimum of 1 pod and up to a maximum of 10 Pods
```
kubectl autoscale deployment wordpress --cpu-percent=50 --min=1 --max=10
```
[(Back to top)](#-table-of-contents)

## Practical Example

#### 1. Apply wordpress deployment
Youâ€™ll notice a slightly modified [wordpress-deployment.yaml](source-codes/Advanced%20Kubernetes%20Usage/Auto-Scaling/wordpress-deployment.yaml) file. This file should look relatively familiar to you. However towards the end of the `containers` specification, youâ€™ll notice a `resources` stanza. Under `resources` it says `requests cpu` of only `100m` them that means 10% of a single core CPU. By severely hampering the CPU, we're able to make it such that nyone pod will hit the limit quite quickly and horizontal autoscaler will find need to intervene much sooner.

![](assets/Advanced%20-%20Auto%20Scaling.assets/Advanced%20-%20Auto%20Scaling-f11c3bbb.png)

We will apply a slightly modified configuration using `kubectl apply -f` command. We'll noticed that the deployment has been configured.
```
kubectl apply -f ./wordpress-deployment.yaml
```
![](assets/Advanced%20-%20Auto%20Scaling.assets/Advanced%20-%20Auto%20Scaling-1c5554f3.png)

#### 2. Add an HPA to Enable Auto-Scaling
Add an HPA to enable auto-scaling on our WordPress installation to keep CPU at 50% average (or lower), with a minimum of 1 Pod and max of 5 Pods
```
kubectl autoscale deployment wordpress --cpu-percent=50 --min=1 --max=5
```
![](assets/Advanced%20-%20Auto%20Scaling.assets/Advanced%20-%20Auto%20Scaling-640ae9e9.png)

#### 3. Simulate Using an Infinite HTTP Request Loop
**Doing in a separate terminal window tab** Simulate load using an infinite HTTP request loop from a worker Pod on our cluster to WordPress to spike our CPU and see how HPA responds.

First letâ€™s run a basic BusyBox image. BusyBox is a utility image that will allow us to run an interactive shell. We will use the `kubectl run` command.

```
kubectl run -i --tty --image=busybox /bin/sh

while true; do wget -q -O- http://wordpress.default.svc.cluster.local; done
```
![](assets/Advanced%20-%20Auto%20Scaling.assets/Advanced%20-%20Auto%20Scaling-d4c7ec76.png)

if you get any error please check [Fix errors](Fix%20errors.md) file.

#### 4. Check the HPA status
Check the HPA status (immediately and after about a minute)
```
kubectl get hpa
```
![](assets/Advanced%20-%20Auto%20Scaling.assets/Advanced%20-%20Auto%20Scaling-1bb51cb0.png)
![](assets/Advanced%20-%20Auto%20Scaling.assets/Advanced%20-%20Auto%20Scaling-16197296.png)


[(Back to top)](#-table-of-contents)

## ðŸ”– Full Kubernetes references & Cheat Sheet
- kubectl reference: https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands
- kubectl cheat sheet: https://kubernetes.io/docs/user-guide/kubectl-cheatsheet/


## ðŸ“™ Source Code Example
- You can download latest code from [here](source-codes).

[(Back to top)](#-table-of-contents)

## ðŸ’¬ Contributing

Your contributions are always welcome! :tada:

1. Fork it!
2. Create your feature branch: `git checkout -b my-new-feature`
3. Commit your changes: `git commit -am 'Add some feature'`
4. Push to the branch: `git push origin my-new-feature`
5. Submit a pull request :D

## ðŸ“œ License

The MIT License (MIT) 2018
> GitHub [@yinkokpheng](https://github.com/yinkokpheng)

[GoDoc]: https://godoc.org/k8s.io/kubernetes
[GoDoc Widget]: https://godoc.org/k8s.io/kubernetes?status.svg
[Submit Queue]: http://submit-queue.k8s.io/#/ci
[Submit Queue Widget]: http://submit-queue.k8s.io/health.svg?v=1
